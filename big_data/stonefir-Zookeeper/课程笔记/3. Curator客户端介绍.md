### 38. zkCli.sh 命令做 CRUD

创建一个节点：create

查看目录：ls

读取数据：get

更新数据：set

删除节点：delete



### 39. Curator: 官方的zk客户端框架



### 40. Curator对zNode基本的CRUD





### 41. ZNode存储Json格式的数据比较好



### 42. 基于CuratorClient来实现的系统的Leader选举的作用：HA主备启动切换

HDFS、Kafka和Canal都用到了ZK进行leader选举

HDFS，NameNode是可以部署HA架构的，主备两台机器，如果主机器宕机了，立马备用的机器可以感知到，立马选举为Leader，作为新的NameNode对外提供服务 

Kafka，有一个很关键的角色，Controller，负责管理整个集群的协作，任何一个Broker都恶意变成Controller，Leader角色 

Canal，部署主备两台机器，主机器挂掉了，备用机器就可以跟上去



### 43. Curator实现Leader选举1:  公平

### 44. Curator实现Leader选举2:  非公平

1. **LeaderLatch：公平排队**
   根据一个根路径，多台客户端在该路径下创建临时顺序节点，例如：leader/node_1,leader/node_2,leader/node_3，节点编号最小的客户端成为leader，没抢到 leader的节点都监听前一个节点的删除事件，在前一个节点删除后重新抢主。

2. **LeaderSelector：非公平抢锁**
   利用分布式锁进行抢主，抢到锁的就是主节点。



### 45. ZK分布式锁: 公平, 非公平

**顺序临时节点 + 监控头节点/前一个结点** 实现非公平/公平锁



### 46. ZK锁应用: 分布式业务系统, 分布式基础架构





### 47. ZK实现Barrier机制

监听+元数据实现barrier



### 48. ZK实现双重Barrier机制

同步屏障(Barrier)是并行计算中的一种同步方法。对于一群进程或线程，程序中的一个同步屏障意味着任何线程/进程执行到此后必须等待，直到所有线程/进程都到达此点才可继续执行下文。

使用请客吃饭的场景：一张桌子坐四个人，四个人都到齐后，才能开饭；四个人都吃完以后，才能离开。



### 49. Barrier一般只有业务场景应用

几乎没用，大部分分布式系统，集群元数据管理 + 监听和通知，Master选举



### 50. ZK实现分布式计数器: 与redis+lua对比

如果真的要实现分布式计数器，应该是用redis来实现，并发量更高，性能更好，功能更加的强大，分布式技术，lua脚本嵌入进去复杂的业务逻辑



### 51. Curator包装zk子节点监听

增删改查做元数据的维护和管理，监听和通知机制，监听元数据的变化得到通知

 

### 53. ZK的数据管理和监听机制应用的典型场景

- **配置中心**, 动态配置
- **集群负载均衡, 注册中心** 



### 54. Curator支持的ZK节点类型: 都支持, 2种类别, 4种组合





### 55. Curator实现ZK分布式队列 TODO: 怎么实现的





### 56. Curator client 功能总结:

1. znode的基本CRUD + 监听和通知 + Leader选举: 分布式中间件系统，分布式大数据系统
2. 分布式锁: 分布式业务系统
3. Barrier、Counters、Queues：基于ZK实现的分布式Barrier、分布式计数器、分布式队列，都不推荐使用，使用场景很少，推荐用Redis做分布式计数，推荐用RabbitMQ / RocketMQ做分布式队列







## Curator 代码原理



### 58. CuratorClient创建: zk连接如何创建

**构造器模式, 创建一个封装zkClient**

ZooKeeper（负责跟zk建立连接） -> Watcher -> 回调CuratorFramework上加的Listerner

1. 构造器模式: 使用CuratorFrameworkFactory.Builder来包装和建立各种属性. build()方法会把属性传给`CuratorFrameworkImpl`, 创建出`CuratorFrameworkImpl`
2. `CuratorFrameworkImpl`维持着所有属性, 还有一个`CuratorZookeeperClient`
3. `CuratorZookeeperClient`包装了一个zookeeperFactory, 
4. `CuratorZookeeperClient.start()`会使用factory创建一个zookeeper
5. `curatorFramework.getZookeeperClient()`会把拿到包装了zookeeper的CuratorZookeeperClient



### 59. Curator创建原生ZK客户端, 并注册watcher

最终的创建是: `return new ZooKeeperAdmin(connectString, sessionTimeout, watcher, canBeReadOnly);`

**这里面的watcher是ConnectionState(继承了watcher), 创建zk原生client的时候把自己当成watcher传进去了.**

所以zookeeperAdmin(继承了Zookeeper这个主类), 到时候收到事件的时候, 就会调用ConnectionState里面的process方法, process里面对应着一个listener队列.















### 68. Leader选举: 临时顺序节点+监听前一个



### 69. Leader选举: 直接拿分布式锁的代码上



















