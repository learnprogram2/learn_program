### 1. zk功能

ZooKeeper: 分布式协调系统, 封装了分布式架构中所有核心和主流的需求和功能:

1. Master选举: 分布式锁
2. 分布式集群的集中式元数据存储
3. 分布式协调和通知



### 2. zk实践

第一类：分布式Java业务系统: 锁

第二类：开源的分布式系统

Dubbo，HBase，HDFS，Kafka，Canal，Storm，Solr 

分布式集群的集中式元数据存储、Master选举实现HA架构、分布式协调和通知

 

第三类: 自研的分布式系统: HA系统

自研分布式系统, 都可以考虑集中式存储分布式集群的元数据? 辅助Master选举实现HA架构？进行分布式协调通知？

 



### 4. zk为了满足分布式系统的需求, 要具备的特性

![01_ZooKeeper架构原理](1.%20ZK%E5%9F%BA%E7%A1%80.assets/01_ZooKeeper%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86.png)

ZooKeeper要支持: 元数据存储, Master选举, 事件通知. 就要满足

1. 集群部署: 不可能单机版本
2. 顺序一致性: 所有请求全部有序
3. 原子性: 要么全部机器都成功，要么全部机器都别成功
4. 数据一致性: 无论连接到哪台ZK上去，看到的都是一样的数据，不能有数据不一致
5. 高可用: 如果某台机器宕机，要保证数据绝对不能丢失
6. 实时性: 通知



### 5. zk架构为了满足特性的特点:

![01_ZooKeeper架构原理](1.%20ZK%E5%9F%BA%E7%A1%80.assets/01_ZooKeeper%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86-1626663249403.png)



1. 集群化部署: 每台机器都在内存保存了zk的全部数据
2. 树形结构的数据模型: znode 数据模型简单, 纯内存保存
3. 顺序写: 集群中只有一台机器可以写, 打上一个全局zxId, 同步到所有机器
4. 数据一致性: 任何一台zk机器收到了写请求之后都会同步给其他机器, 保证数据的强一致
5. 高并发: 内存数据
6. 高可用: 集群每个都有全部数据, 只要挂掉不超过一半, 都可以正常维护集群.



### 6. ZK集群三种角色: Leader, Follower, Observer

![01_ZooKeeper架构原理](1.%20ZK%E5%9F%BA%E7%A1%80.assets/01_ZooKeeper%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86-1626664311384.png)

1. 集群启动自动选举Leader: 只有Leader是可以写的
2. Follower参与选举, 只同步数据和提供数据的读取
3. Observer不参与选举, 接收数据, 提供数据读取. 不是必须的



### 7. Client和zk连接: 长连接, session概念

![01_ZooKeeper架构原理](1.%20ZK%E5%9F%BA%E7%A1%80.assets/01_ZooKeeper%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86-1626665540007.png)



1. zk集群启动之后, 分配好角色
2. 客户端就会跟zk建立TCP长连接
3. 每个长连接就是一个session, 中间有心跳. 只要客户端在sessionTimeout时间内重新连接zk一台机器, 就能继续保持session, 否则session就超时.



### 8. ZK的数据模型: 不同类型的znode

1. znode数据结构

   ```json
   {
       "stat":"数据版本",
       "version":"znode版本",
       "cversion":"znode子节点版本",
       "aversion":"acl权限控制版本"
   }
   ```

2. **Znode类型**

   - 持久节点, 临时节点
   - 普通节点, 顺序节点



### 9. ZK机制: Watcher监听回调

**客户端对指定znode进行Watcher监听, znode改变的会回调通知客户端**

写数据, 主动读取数据, 监听数据变化



### 10. 集群内数据一致性保证: ZAB(ZooKeeper Atomic Broadcast)原子广播协议 - TODO Paxos

zk集群的数据同步用的是设计的ZAB协议, ZooKeeper Atomic Broadcast ZooKeeper原子广播协议.



### 11. ZAB: 主从同步机制, 崩溃恢复机制

![01_ZooKeeper架构原理](1.%20ZK%E5%9F%BA%E7%A1%80.assets/01_ZooKeeper%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86-1626673378838.png)

**协议的本质: 划分集群的Leader和Follower两种角色**

只有Leader可以接受写操作, Leader和Follower都可以读. 

Leader收到事务请求, 转换为事务Proposal(提议)同步给所有的Follower. 

超过半数的Follower都说收到事务proposal了, Leader再给所有的Follower发一个Commit, 所有Follower提交一个事务.

而且如果Leader崩溃了, 要重新选举Leader保证继续运行

**角色划分，2PC（两阶段），过半写机制**



### 12. ZAB协议工作流程 TODO







### 13. ZAB广播协议: 2PC提交思想

![01_ZooKeeper架构原理](1.%20ZK%E5%9F%BA%E7%A1%80.assets/01_ZooKeeper%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86-1626678318511.png)

每一个消息广播的时候，都是2PC思想走的，先是发起事务Proposal的广播，就是事务提议，仅仅只是个提议而已，各个follower返回ack，过半follower都ack了，就直接发起commit消息到全部follower上去，让大家提交.

1. 每个proposal被分配全局的递增txId.

2. leader会为每个follower创建一个队列, 里面放入要发送给follower的事务proposal, 保证同步的顺序性

3. follower收到事务proposal, 需要立即写入本地磁盘日志中, 写入成功就可以保证数据安全, 返回ACK.

4. 过半follower都返回了ack, leader推送commit消息给全部follower

5. commit之后, 数据可以被读取到了.



### 14. ZAB: 最终一致性(顺序一致性)保证

zk官方给自己的定义：顺序一致性

因此zk是最终一致性的，但是其实他比最终一致性更好一点，出去要说是顺序一致性的，因为leader一定会保证所有的proposal同步到follower上都是按照顺序来走的，起码顺序不会乱

如果要求强一致性，可以手动调用zk的sync()操作





### 15. ZAB的数据一致性问题

1. **leader在发送commit消息前挂掉**
   - 新leader发现ack没有接收到commit, 检查集群ack状态, 然后决定是否commit消息
2. leader接收到消息, 没有发送precommit消息, 就挂掉
   - 新leader起来发现没有这条消息, 就丢掉.



### 16. Leader挂掉后新leader如何同步. 何时提供服务

其他的follower就会跟他进行同步，他给每个follower准备一个队列，然后把所有的proposal都发送给follower，只要过半follower都ack了，就会发送commit给那个follower

 

所谓的commit操作，就是把这条数据加入内存中的znode树形数据结构里去，然后就对外可以看到了，也会去通知一些监听这个znode的人

 

如果一个follower跟leader完全同步了，就会加入leader的同步follower列表中去，然后过半follower都同步完毕了，就可以对外继续提供服务了



### 17. Leader挂掉, 对于未处理的消息, 新leader是如何丢弃的

每一条事务的zxid是64位的，高32位是leader的epoch，就认为是leader的版本吧；低32位才是自增长的zxid

- leader自己刚把一个proposal写入本地磁盘日志，就宕机了，没来得及发送给全部的follower，此时新leader选举出来，他会的epoch会自增长一位

- 然后老leader恢复了连接到集群是follower了，此时发现自己比新leader多出来一条proposal，但是自己的epoch比新leader的epoch低了，所以就会丢弃掉这条数据

**对外提供服务的时候，2PC + 过半写机制，顺序一致性（最终的一致性）**



### 18. Ovserver节点

Ovserver只是单纯的接收数据，同步数据，可能数据存在一定的不一致的问题

集群的读取, follower起码有2个或者4个保证集群的HA, 但是follower太多了也不太好, 数据一致性达成会出现延迟.



### 19. ZK适合读多写少的, 小follower集群

zk适合读多写少的, 只有leader在接受写请求.





















