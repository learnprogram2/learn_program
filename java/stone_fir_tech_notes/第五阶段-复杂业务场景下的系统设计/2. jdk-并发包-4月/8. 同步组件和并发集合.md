## 同步组件: CountdownLatch



### 156. 应用: DataNode启动时向NameNode注册自己







## 同步组件: CyclicBarrier:  一起等待满足数量跳闸

![image-20210428161620766](8.%20CountdownLatch-Concurrent.assets/image-20210428161620766.png)



### 161. 案例: 聚合操作时候等待所有结果

一般不常用, 而且一般有别的方法能解决这种等待的问题.





## 同步组件: Semaphore信号量: 满足指定数量跳闸

等待指定数量的线程完成任务即可

### 163. 基于AQS等待指定数量的线程: 尝试拿state

```java
// 创建semaphore, 设置初始的state
Semaphore semaphore = new Semaphore(5);
// 扣减state, 如果state>1, 拿state成功, 就不阻塞, 如果state不够, 就阻塞.
//      阻塞醒来之后还是tryAcquire,尝试扣减state, 如果.... 循环.
semaphore.acquire();
// 增加state, 然后把队列里的node叫醒.
semaphore.release();
```



### 166. 实战: semaphore实现分布式计算系统的推测执行

有N台机器, 把一个任务交给N台中的一个, 可以看一下哪个先返回.



## Exchange







## 并发集合1: ConcurrentHashMap

### 168. HashMap考点: 

HashMap的原理

- hash算法
- rehash过程, 扩容的过程
- ConcurrentHashMap的原理是什么



### 169. HashMap扩容头插法并发死循环

>  HashMap之所以在并发下的扩容造成死循环: 头插法
>
> -  一个线程先期完成了扩容, 链表变成了倒序
> - 后一个线程再扩容时, 再次将倒序链表变为正序链表
> - **于是形成了一个环形链表, 当表中不存在的元素时, 造成死循环**
> - JDK8是用 head 和 tail 来保证链表的顺序和之前一样，这样就不会产生循环引用。

```java
// 1. 先计算一下hashcode, &算出index, 然后校验一下index的位置有没有当前的k, 如果有就update改value.
// 2. 纯纯的添加一个entry
    void addEntry(int hash, K key, V value, int bucketIndex) {
        // 1. 就是把原来链表里的元组拿出来, 然后创建新元素, next指向原来链表, 然后塞进去.
        Entry<K,V> e = table[bucketIndex];
        table[bucketIndex] = new Entry<>(hash, key, value, e);
        // 2. 这里是检查一下, 是不是到了扩容的阶段了. 容量*factor(0.75)
        if (size++ >= threshold)
            resize(2 * table.length);
    }
// 3.1 不行了, 要扩容了
    void resize(int newCapacity) {
        // 0. 校验了一下最大容量, 其实没啥用.

        // 1. 直接创建一个新的table.
        Entry[] newTable = new Entry[newCapacity];
        // 2. 把老的元素转移到新的table里面.
        transfer(newTable);
        // 3. 把table替换掉. 修改掉新的阈值.
        table = newTable;
        threshold = (int)(newCapacity * loadFactor);
    }
// 3.2 扩容就要把老的转入新的table.
    void transfer(Entry[] newTable) {
        Entry[] src = table; // 把老的先拿到
        int newCapacity = newTable.length;

        for (int j = 0; j < src.length; j++) {
            Entry<K,V> e = src[j];
            if (e != null) {
                src[j] = null;
                do {
                    Entry<K,V> next = e.next;
                    int i = indexFor(e.hash, newCapacity);
                    // 这里开始遍历原来的link, 然后头插法入新的table
                    e.next = newTable[i];
                    newTable[i] = e;
                    e = next;
                } while (e != null);
            }
        }
    }
```





### 172. ConcurrentHashMap: 分段加锁的思想实践

HashMap里面是一个table数组盛放所有数据, 没有加任何锁, 会有并发问题.

HashTable是一个table+synchronized锁了全表. get都锁, 并发性能较低.

ConcurrentHashMap，分段加锁，把一份数据拆分为多个segment



- refactor=0.75: **在加载因子为0.75时，每个碰撞位置链表长度超过8个的概率便小于千万分之一**, 泊松分布.



### 173. 初始化 initTable(): cas+volatile保证并发

```java
//  volatile的变量CAS操作保证了可见性原子性
	private final Node<K,V>[] initTable() {
        Node<K,V>[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            if ((sc = sizeCtl) < 0)
                // 如果别人正在创建, 就空转等待.
                Thread.yield(); // lost initialization race; just spin
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                // 这里是拿到了一个创建锁, 是一个volatile的变量CAS操作保证了可见性原子性.
                try {
                    if ((tab = table) == null || tab.length == 0) {
                        // 初始16. 创建一个16的table就好了.
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;
                        sc = n - (n >>> 2); // sc=12
                    }
                } finally {
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
```

### 174. 未分段数组的CAS加锁: put第一个kv的情况: CAS操作table

> 刚开始其实就一个数组，没有分段的概念，对数组里的赋值，是依托CAS，硬件级别的MESI协议的原理
>
> - **CAS操作table, 保证原子性.** 硬件上锁定了内存地址修改.

```java
if (casTabAt(tab, i, null,
             new Node<K,V>(hash, key, value, null))) // 创建一个node
    break;                   // no lock when adding to empty bin
// 直接就是自旋+Unsafa的CAS操作.
```



### 176. Put遇到hash冲突: 分段加锁: synchronized锁第一个node

这个分段的粒度, 其实就是table里面每个cell.

```java
            else {
                // 2.4 其他情况, 应该是正常的有一个node, 但不是迁移的状态了.
                V oldVal = null;
                synchronized (f) { // 锁上第一个node.
                    if (tabAt(tab, i) == f) { // 再校验一下
```





### 177. Put遇到hash冲突: 链表/红黑树插入元素

```java
synchronized (f) { // 锁上第一个node.
    if (tabAt(tab, i) == f) { // 再校验一下
        if (fh >= 0) { // 如果first的hash>0, 说明没被修改过...具体改成负的有什么用还不知道.
            binCount = 1;
            // 遍历链表
            for (Node<K,V> e = f;; ++binCount) {
                K ek;
                // 1. 如果key相同, 就修改.
                if (e.hash == hash &&
                    ((ek = e.key) == key ||
                     (ek != null && key.equals(ek)))) {
                    oldVal = e.val;
                    if (!onlyIfAbsent) // 只要不是只添加, 就update.
                        e.val = value;
                    break; // 跳出去就好了.
                }
                // 2. 没有相同的key, 就挂在链表最后一个. 跳出去.
                Node<K,V> pred = e;
                if ((e = e.next) == null) {
                    pred.next = new Node<K,V>(hash, key,
                                              value, null);
                    break;
                }
            }
        }
        else if (f instanceof TreeBin) { // 这里是first的hash肯定是负数, 然后firstNode是TreeBin
            //      treeBin是Tree挂在table的东西, treeBin里面不放东西.
            //      treeBin也会被当作读写锁,
            Node<K,V> p;
            binCount = 2;
            // 这是添加到tree里面一个合适的node
            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                  value)) != null) {
                // 如果key有相同的, 看看让不让修改, 让的话就修改了就完了.
                oldVal = p.val;
                if (!onlyIfAbsent)
                    p.val = value;
            }
        }
    }
}
// 3. 看一下该不该树化. 只要是正常插入到了link和tree里面就会进来的
if (binCount != 0) {
    // 链表超过了8个, 就开始树化了
    if (binCount >= TREEIFY_THRESHOLD)
        treeifyBin(tab, i);
    if (oldVal != null)
        // 如果是修改, 就把oldValue返回去.
        return oldVal;
    break;
}
```



### 178. put之后增加count: 检查扩容

```java
// 1. put之后都会给count+1
addCount(1L, binCount);

private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;
    // count看来是用了addr的机制,有一个bastCount, 还有一个count数组.
    // 1. 下面这个if就是count++, 使用了addr累加器的概念.
     
    // 2. 这里就是扩容检查了.
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        while (
            // 如果当前的count>临界值sizeCtl, 并且table !=null, 并且table还可以扩容.
            s >= (long)(sc = sizeCtl) && (tab = table) != null &&
            (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);
            if (sc < 0) {
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex <= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs << RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}
```



### 补充: 扩容transfer流程 TODO







### 179. 查询操作不涉及锁: unsafe.getObjectVolatile查询保证可见性

1. 原来没有, 新增. 其他线程可以在CAS添加后拿到.
2. 原来有, 修改, 也可以unsafe.getObjectVolatile查到.

- 因为不加锁, 所以不保证读完一瞬间没人修改.



### 180. 相比1.7 分段粒度更细

1.7: 分为16个segment, 每个segemnt一把锁. 

1.8: 每个cell都是一个segment.



### 181. 应用: 注册中心的注册表使用ConcurrentHashMap TODO







