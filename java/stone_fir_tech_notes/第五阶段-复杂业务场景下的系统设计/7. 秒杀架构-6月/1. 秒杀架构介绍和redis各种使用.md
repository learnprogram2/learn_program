## 秒杀架构设计介绍

**Java面试中问秒杀架构, 因为涉及到大部分的知识点.**




### 4. 秒杀促销活动服务的业务流程 & 前端页面优化

1、秒杀促销活动服务

（1）秒杀促销活动服务的业务流程

（2）秒杀促销活动的Redis数据结构设计

 

电商运营人员会在你的这个服务里选择对应的一些热门的商品，给他一个超低折扣，锁定他的一些库存，专门是用于进行秒杀促销活动的售卖，这个服务会把你选择好的商品信息、折扣信息、促销活动信息、库存数据，都放到一个redis里去

 

2、秒杀促销活动的前端页面

 

（1）秒杀活动页面静态化方案

（2）页面静态化以及CDN缓存方案

（3）静态页面的缓存以及文件服务器存储

（4）秒杀后台接口url隐藏方案

（5）后端与前端时钟同步的秒杀倒计时方案

（6）秒杀场景下的前端验证码方案

（7）秒杀活动页面的限流方案



### 5. 高并发负载均衡 和 高并发架构设计

 

3、秒杀场景下的高并发负载均衡架构

 

（1）防黑客DDoS攻击的高防IP方案

（2）秒杀场景下的SLB负载均衡架构方案

（3）基于SLB的秒杀场景和普通场景的分流隔离

（4）秒杀场景的Nginx请求分发方案

（5）Nginx环节的请求限流方案

（6）高并发场景下的Nginx内核参数调优

 

 

4、 秒杀场景的高并发抢购架构设计

 

（1）秒杀抢购请求的黄金链路流程

（2）高并发场景下的Tomcat内核参数性能调优

（3）秒杀场景下的接口限流方案

（4）重复秒杀请求去重解决方案

（5）秒杀接口的防刷防作弊风控解决方案

（6）秒杀场景的Redis分布式缓存架构方案

（7）基于Redis Lua脚本实现的复杂秒杀业务逻辑

（8）秒杀场景下的库存超卖问题解决方案

（9）秒杀场景下的多线程并发优化实战

（10）高并发场景下的线程池参数调优

（11）秒杀场景下的多线程同步加锁优化实战

（12）秒杀场景下的分布式锁优化实战

（13）秒杀场景下的Disruptor以及内存队列实战

 

### 6. 异步下单技术方案 & 下单后的业务逻辑

5、秒杀场景的异步下单技术方案

 

（1）秒杀场景下的RocketMQ集群架构方案

（2）秒杀场景下的消息队列技术方案

（3）秒杀场景下的Redis+RocketMQ一致性回滚方案

（4）秒杀场景下的数据库架构方案

（5）秒杀场景的分库分表技术方案

（6）秒杀超高并发场景下的数据库压测

（7）高并发场景下的数据库连接池参数调优

（8）高并发场景下的数据库内核参数调优

（9）秒杀下单服务的核心业务逻辑实现

（10）高并发场景下的数据库锁实战

 

6、秒杀成功后的业务逻辑实现

 

（1）秒杀成功后的异步通知用户解决方案

（2）秒杀成功后的订单查询方案

（3）秒杀成功后的订单支付以及后续逻辑实现

（4）秒杀成功后长期不支付解决方案

 

### 7. 高可用 & 压测监控

7、高可用的秒杀系统架构设计

 

（1）秒杀系统的全链路中间件高可用架构

（2）秒杀系统的全链路高可用降级方案

（3）Redis缓存崩溃后的秒杀系统自动恢复方案

（4）RocketMQ集群崩溃后的临时本地存储降级方案

（5）数据库集群崩溃的临时本地存储降级方案

（6）秒杀服务崩溃的防服务雪崩降级方案

（7）秒杀系统的全链路漏斗式流量限制方案

（8）秒杀系统的双机房多活部署方案

（9）秒杀系统部分机房故障时的降级方案

 

 8、秒杀系统的压测、故障演练以及实时大盘

 

（1）秒杀系统的全链路压测以及针对性优化

（2）秒杀系统的全链路故障演练以及高可用架构验证

（3）秒杀系统的基于大数据技术的实时数据大盘

 

9、秒杀业务中台的架构升级与改造

 把系统升级成中台, 各种小应用场景都可以接入.

 







## 案例实战: Redis实践

### 10. 基于Redis的缓存机制-简单存取kv

可以放任何想要的东西, 甚至是html页面. **高并发和高性能.**





### 11. 简单的分布式锁: set k v nx

redission中的分布式锁是lua+setNx命令实现的.



### 12. 博客网站的文章发布与查看

- `mset, mget` 来批量设置kv.
- 文章双写: 写入数据库, 把<id, 文章>存储redis



### 13. 文章字数统计 和 预览前N字

- `strlen`: 总长度
- `getrange`: 拿一部分数据



### 14. 用户操作日志审计功能

- 日志存储: 按天存储 <userId:day, logs>
- log追加: append命令往后加操作.



### 15. 简单的唯一ID生成

- `incr` 命令 简单的自增. 可以在分库分表中做一个分表依据.
- snowflake算法, leaf算法都是依靠: 多个机器各自生成自己的id



### 16. 文章点赞计数器: incr&decr



## 案例实战: Redis实践-数据结构

### 18. 社交网络网址点击追踪机制: hash结构

社交网站（微博）一般会把你发表的一些微博里的长连接转换为短连接，这样可以利用短连接进行点击数量追踪，然后再让你进入短连接对应的长连接地址里去

1. **转成短链接**: 可以使用一个自增ID, 把ID10进制转36进制(为了更短), 把URL和短链接关联上
2. **Hash存储:** {key, [<点击次数, num>, 短链, 长链, ...]}

```java
short_url_access_count: {
	http://t.cn/XsGGA9d: 152,
	http://t.cn/I93yUUaF: 269
}
```



### 21. 文章计数器: hash结构

` hincrby 文章key  view_count 1`: 查看计数+1

`hget 文章key view_count`: 拿到文章的查看次数

```java
jedis.hmset("article::" + id, blog: Map);
```



### 24. Hash操作内存中的文章信息

- `hexists key` 查看文章是不是存在
- `hgetall key` 拿到文章所有信息
- `hmset key` 更新多个字段
- 字符串kv的操作: getrange，setrange，append
- 过期时间 `expire nx key`



### 27. 用户会话缓存

老师做的:

1. 一个存放token的hash, 存放userId的token
2. 一个存放token TTL的hash, 然后人工检查存活时间

- 有点麻烦. 不知道这回不会产生脏数据.



### 30. redis: 秒杀排队-公平队列

**公平秒杀方案是:** 把所有请求加入到redis队列里, consumer消费, 一次扣减库存, 返回秒杀结果.

**非公平秒杀**: 要注意库存扣减.

- `lpush`, `lpop` 左侧的栈操作
- `rpush`, `rpop` 右侧的栈操作.





### 32. 博客网的分页浏览

博客的发表和修改，查看一个博客的详细内容，浏览次数和点赞次数的统计

1. 可以把一个人的所有博文塞到一个list里面
2. **分页查询=range查询**`lrange user_blog_list startIndex endIndex`
3. list的总长度`llen user_blog_list`



### 35. OA系统的待办事项: list数据结构

lindex，lset，linsert，ltrim，lrem

- 新增待办事项，lpush list event

- 插入待办事项，linsert list index event

 

### 36. 邮件验证: list任务队列+验证码kv



### 37. 网站UV数据去重: SET结构存放userId

- `sadd` 存放用户访问量



### 38. 博客文章标签管理: 一个标签一个Set

- `srem`: 删除元素, `sadd`添加元素
- `del`: 删除标签
- `sismember`, `smembers` 拿到所有文章



### 39. 点赞功能实现: 一条推文一个set

- sadd给某一条朋友圈添加点赞的一个好友
- 用户取消点赞的话，那就是srem删除某个好友的点赞
- 查看你是否对某条朋友圈进行过点赞，sismember
- 你发出的朋友圈被哪些人点赞了，smembers
- 你的朋友圈的点赞次数，scard

`真实, 肯定不是这样的, 我觉得可能要多存一点数据吧, 然后后台多计算一点`



### 41. 投票: 每个投票一个set, 存放用户投票纪录



### 42. 微博社交关系: 关注列表, 粉丝列表  set



### 43. 共同关注和推荐关注: set取交集, 取差集

- `sinter set1 set2` 取交集，就是共同关注好友
- `sdiff set1 set2`获取差集,
- `sunion set1 set2` 如果+store还可以存储



### 44. 抽奖: 所有人在set中, srandMember弹一个

- `srandmember`随机弹出来一个.



### 45. 商品搜索->反向索引

也是按照关键词为key, 把相关商品放在set里面.

为商品添加索引，sadd，给商品添加一个关键词索引集合，sadd把商品添加到每个关键词的商品集合里去，删除商品是一个反向的过程，走srem，获取一个商品所有的关键词，smembers，根据某几个关键词去搜索商品，对每个关键词都smembers一下拿到商品集合，然后走一个sintern对多个集合进行交集

 

### 46. 流行音乐排行榜: sorted-set结构

不能有重复数据结构, 加入每个数据带一个分数.

- `zadd key value score` 添加元素
- `zincrby` 增加分数

- `zrevrange`拿到排名前n的元素



### 47. 新闻推荐: sorted-set选择指定分数范围内的数据

zadd，把当日最新的新闻加入到一个集合里，zrem是删除某个新闻，zcard是统计当日最新新闻，，zrevrangebyscore max_time min_time start_index count withscores，是说按照他的时间分数进行倒序排序，然后获取指定的分页，zcount 可以获取指定分数范围的数量





### 48. 同类型相关产品推荐

zremrangebyscore，zunionstore，zinterstore

买了一个商品，他会给你推荐一个列表，购买过此商品的顾客也同时购买了其他XX商品，这个也是可以用这个sorted set来实现的

**对每个顾客，每次购买了之后，都会遍历他之前购买过的所有的商品，对每个商品都维护一个同时购买的其他商品的数量，可以用zincrby set 1 其他商品，然后后续如果要看到某个商品购买的人还购买了其他哪些商品，就可以用zrevrange set start_index end_index withscores**，







### 50. 搜索框自动补全: zset, 仿佛是es做更好啊.

zrangebylex、zrevrangebylex、zlexcount、zremrangebylex、zpopmax、zpopmin、bzpopmax、bzpopmin

 

对于输入的每个搜索词，都会遍历一下，拼接出来，然后zincrby auto_complete::潜在搜索词 权重 完整搜索词，这样的话，就是每个潜在搜索词都会有一个集合，集合里是各种可能对应的搜索词和权重分数

 

然后真正你搜的时候，把你输入的潜在搜索词去执行，zrevrange set 0 9，就是对这个潜在搜索词按照权重分数倒序拿出最近的10个搜索词，做一个自动提示和补全

```java
// 为每个前缀维护一个zset, 把结果都当成元素存起来, 这样每次结果把元素分数+1, 就有排序了.
jedis.zincrby(
    "potential_Keyword::" + potentialKeyword.toString() + "::keywords",
    new Date().getTime(),
    keyword);
```









## 案例实战: Redis实践-事务, Lua, pipeline, geohash, hyterloglog



### 52. hyterloglog: 网页重复垃圾数据的快速去重

- `pfadd key content` 往hyterLogLog结构里面塞一个内容, 然后以后再塞返回0, 说明有了.



### 53. 月活跃用户数统计: pfmerge 多个hyperloglog记录

pfmerge 多个hyperloglog，可以算出来周、月和年的活跃用户数



### 54. 位图记录用户行为每日操作记录: bitmap 

setbit key user_id 1

getbit key user_id

bitcount key

### 55. GeoHash计算距离



### 56. GeoHash-附近的人

- `geoadd key longitude latitude user` 记录用户位置
- `georadiusbymember `查询一定范围内的其他元素

### 57. 给key设定过期时间

set key value

expire key timeout



### 60. 超时自动释放锁:

`set key value ex=timeout nx=true`



### 60. 冷数据自动淘汰的自动补全程序

`expire key timeout`





### 61. 支持身份验证功能的分布式锁释放机制: 就是redission的锁LUA脚本

 ```java
pipeline = pipeline() // 流水线里的命令，都是一次性打包发送执行的
try {
    pipeline.watch(key) 
	// key如果有变化，后续提交事务直接失败，unwatch可以取消监控
	lock_value = pipeline.get(key)
    if(lock_value == null) {
       // 锁已经被释放了
	} else if(lock_value == user_id) {
  		// 是自己加的锁，可以释放
  		// 先用multi()打开一个事务，事务里的命令一起成功或者一起失败
  		pipeline.multi()
  		pipeline.delete(key)
  		pipeline.execute() // 提交事务，discard可以放弃事务
	} else {
  		// 不是自己加的锁，不能让你去释放
	}
} catch() {
    // 如果有异常说明你提交事务的时候有人更新了key
} finally {
    // 每个流水线都绑定了一个连接   
	// 执行完一个流水线，必须执行reset把连接还给连接池
    pipeline.reset()
}
 ```



stream，发布/订阅，lua

















