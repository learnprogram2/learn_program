### 146. 高可用架构是 有预案, 保证正常功能: 

如果说你的系统出现了一些故障，但是此时你有一些预备的预案，此时系统还可以正常运转，也许功能上有点打折扣，但是基本还能正常跑，这个时候就可以说你的系统是高可用的，可用性，99%，99.9%，99.99%，99.999%



### 147. 秒杀系统全链路高可用-技术点

1. **LVS高可用: LVS双机部署+keepalived**
2. **Nginx高可用**: 多机部署, LVS做负载均衡.
3. **秒杀服务高可用**: 就是多布几台
4. Redis: Cluster master-slave架构
5. MQ: 副本冗余, 集群部署
6. **秒杀下单服务:** 多部几台
7. **秒杀库存服务 / 订单服务:** 多部几台



### 148. Redis崩毁后的 秒杀系统的 自动恢复方案

- **对秒杀服务:** 没办法接着锁定库存了.
  - 可以把秒杀抢购流水日志顺序, 写入OS cache, 返回: 正在抢购中.
  - 之后的秒杀请求直接返回错误码什么的.降级.
- 前端拿到正在抢购中, 就生成一个抢购中的页面. 用户可以等着, 或者另外抢购.

- redis恢复后, 秒杀服务接着把写入OS cache的请求重新走流程.





### 149. Redis崩溃之后的重启丢失数据 -> 库存超卖

redis的master-slave, slave切换的时候会丢失数据.

1. **取消Master-slave模式: 只用几台独立的redis.**
   - **搭配上AOF的always刷盘方式**
2. **依靠订单系统检查, 校验防止订单超卖** 不太好.



### 150. MQ集群崩溃的 秒杀服务降级方案

MQ崩溃后, 

1. **MQ上的数据保证不丢失就好了,之后会重新给下单, 然后如果超时会被秒杀下单给视为积压, 取消下单, 释放库存**
2. **秒杀服务把给下单服务的通知写入内存, 线程池慢慢调用秒杀下但服务就好了**



### 151. 系统订单服务异常后: 通过MQ重试 和 死信方案

**秒杀下单服务调用订单系统异常:** 此时需要基于MQ的重试队列进行重试，重试几次都不行，需要进入死信队列，专门有处理死信的线程，间隔比如1小时后再进行反复重试



### 152. 秒杀抢购 和 下单系统的高可用保证方案

- 秒杀抢购系统多机器部署

- redis和mq崩溃的情况他都已经考虑到了
- **下单系统宕机: MQ消息积压过久, 此时方案已经说过了, 快速释放库存, 让用户分散重新下单就行了**
- 秒杀服务要监控下单服务是否异常, 如果异常就要回撤订单.



### 153. 秒杀抢购与下单的异构存储*分布式事务方案*

**秒杀服务把 Redis扣减库存 和 MQ提交下单MQ 合成一个事务**

1. **如果发送通知给MQ失败了，此时走降级方案，写内存以及保存到本地磁盘，执行成功了，这个事务也算是成功了**

**redis事务+MQ事务(kafka可以用多次重试+降级)，异构存储混合事务**



### 154. 多机房多活部署以及单机房故障降级 

讲一下多机房多活方案，但是不会讲解在秒杀系统里的落地实践，那一定是整个公司完整的系统全部做成双机房多活，不只是秒杀系统一个人的问题



### 155. 全链路压测, 高可用演练

先基于虚拟机环境各种部署和开发代码，演练，做一个模拟的本地全链路压测，每秒1000请求，每秒500请求，做 一些高可用演练，真实平台去做一个集成，会做一些代码改造，跟真实电商平台集成在一起

![秒杀系统架构图](146-155.%20%E7%A7%92%E6%9D%80%E6%9E%B6%E6%9E%84%E5%85%A8%E9%93%BE%E8%B7%AF%E9%AB%98%E5%8F%AF%E7%94%A8.assets/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E5%9B%BE.png)

![image-20210622165911180](146-155.%20%E7%A7%92%E6%9D%80%E6%9E%B6%E6%9E%84%E5%85%A8%E9%93%BE%E8%B7%AF%E9%AB%98%E5%8F%AF%E7%94%A8.assets/image-20210622165911180.png)





















